{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2444199,"sourceType":"datasetVersion","datasetId":1131669}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:11:03.920870Z","iopub.execute_input":"2025-04-16T22:11:03.921090Z","iopub.status.idle":"2025-04-16T22:11:16.664216Z","shell.execute_reply.started":"2025-04-16T22:11:03.921068Z","shell.execute_reply":"2025-04-16T22:11:16.663597Z"}},"outputs":[{"name":"stderr","text":"2025-04-16 22:11:05.621137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744841465.825399      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744841465.883620      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"2.18.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"benjaminawd/new-york-times-articles-comments-2020\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:16:11.401973Z","iopub.execute_input":"2025-04-16T20:16:11.402270Z","iopub.status.idle":"2025-04-16T20:16:11.978721Z","shell.execute_reply.started":"2025-04-16T20:16:11.402251Z","shell.execute_reply":"2025-04-16T20:16:11.977966Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/new-york-times-articles-comments-2020\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\nimport random\n\n# Load dataset\narticles_path = '/kaggle/input/new-york-times-articles-comments-2020/nyt-articles-2020.csv'\ndf = pd.read_csv(articles_path, usecols=['headline'])\ndf.dropna(inplace=True)\n\n# Prepare text data\nheadlines = df['headline'].astype(str).tolist()\n\n# Tokenization\ntokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(headlines)\ntotal_words = 5000\n\ninput_sequences = []\nfor headline in headlines:\n    token_list = tokenizer.texts_to_sequences([headline])[0]\n    for i in range(1, len(token_list)):\n        input_sequences.append(token_list[:i+1])\n\ninput_sequences = input_sequences[-100000:]  # cap to 100k\nmax_sequence_length = max(len(seq) for seq in input_sequences)\ninput_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n\nX, y = input_sequences[:, :-1], input_sequences[:, -1]\n\nmodel = Sequential([\n    Embedding(total_words, 64, input_length=max_sequence_length-1),\n    LSTM(64),\n    Dense(64, activation='relu'),\n    Dense(total_words, activation='softmax')\n])\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X, y, epochs=30, verbose=1)\n\n\n\n# Generate new headlines\ndef generate_headline(seed_text, next_words=10):\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n        output_word = tokenizer.index_word.get(predicted[0], \"\")\n        seed_text += \" \" + output_word\n    return seed_text\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:16:12.369611Z","iopub.execute_input":"2025-04-16T20:16:12.369896Z","iopub.status.idle":"2025-04-16T20:22:52.633910Z","shell.execute_reply.started":"2025-04-16T20:16:12.369873Z","shell.execute_reply":"2025-04-16T20:22:52.633252Z"}},"outputs":[{"name":"stderr","text":"2025-04-16 20:16:14.481591: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744834574.738392      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744834574.809727      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\nI0000 00:00:1744834589.887786      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1744834589.888487      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1744834594.166323      93 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.1202 - loss: 6.6883\nEpoch 2/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.1412 - loss: 6.0839\nEpoch 3/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.1628 - loss: 5.7786\nEpoch 4/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.1686 - loss: 5.5672\nEpoch 5/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.1799 - loss: 5.3817\nEpoch 6/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.1846 - loss: 5.2282\nEpoch 7/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.1943 - loss: 5.0744\nEpoch 8/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.1990 - loss: 4.9429\nEpoch 9/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.2034 - loss: 4.8109\nEpoch 10/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.2132 - loss: 4.6939\nEpoch 11/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.2199 - loss: 4.5764\nEpoch 12/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.2230 - loss: 4.4621\nEpoch 13/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.2274 - loss: 4.3640\nEpoch 14/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.2339 - loss: 4.2706\nEpoch 15/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.2383 - loss: 4.1902\nEpoch 16/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.2468 - loss: 4.0940\nEpoch 17/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.2489 - loss: 4.0237\nEpoch 18/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.2584 - loss: 3.9423\nEpoch 19/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.2629 - loss: 3.8764\nEpoch 20/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.2689 - loss: 3.8060\nEpoch 21/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.2769 - loss: 3.7337\nEpoch 22/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.2819 - loss: 3.6749\nEpoch 23/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.2894 - loss: 3.6083\nEpoch 24/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.2954 - loss: 3.5451\nEpoch 25/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.3024 - loss: 3.4931\nEpoch 26/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.3113 - loss: 3.4316\nEpoch 27/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.3175 - loss: 3.3785\nEpoch 28/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.3253 - loss: 3.3196\nEpoch 29/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.3333 - loss: 3.2619\nEpoch 30/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.3383 - loss: 3.2285\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(generate_headline(\"Breaking news\"))\nprint(generate_headline(\"new release\"))\nprint(generate_headline(\"white house\"))\nprint(generate_headline(\"wall street\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:26:51.550514Z","iopub.execute_input":"2025-04-16T20:26:51.550817Z","iopub.status.idle":"2025-04-16T20:26:54.171052Z","shell.execute_reply.started":"2025-04-16T20:26:51.550793Z","shell.execute_reply":"2025-04-16T20:26:54.170393Z"}},"outputs":[{"name":"stdout","text":"Breaking news <OOV> leave the pandemic to <OOV> <OOV> uncertainty and confusion\nnew release old <OOV> <OOV> of <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\nwhite house <OOV> the <OOV> of <OOV> <OOV> <OOV> <OOV> <OOV> <OOV>\nwall street rallies for a storm <OOV> skies were seven 15 years\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"Instead of always picking the most probable word (argmax), you now:\n\n✅ sample_with_temperature(preds, temperature)\nAdds randomness to predictions by adjusting the temperature.\n\nA lower temperature (e.g., 0.2) makes the model more confident and conservative (picks high-probability words).\n\nA higher temperature (e.g., 1.5) makes it more adventurous and diverse (picks from broader options).","metadata":{}},{"cell_type":"code","source":"def sample_with_temperature(preds, temperature=1.0):\n    preds = np.asarray(preds).astype(\"float64\")\n    preds = np.log(preds + 1e-7) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\ndef generate_headline(seed_text, next_words=10, temperature=1.0):\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n        preds = model.predict(token_list, verbose=0)[0]\n        predicted_index = sample_with_temperature(preds, temperature)\n        output_word = tokenizer.index_word.get(predicted_index, \"\")\n\n        if output_word and output_word != \"<OOV>\":\n            seed_text += \" \" + output_word\n        # Optional: else skip adding <OOV> or unknown word\n\n    return seed_text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:28:42.006564Z","iopub.execute_input":"2025-04-16T20:28:42.007399Z","iopub.status.idle":"2025-04-16T20:28:42.013655Z","shell.execute_reply.started":"2025-04-16T20:28:42.007372Z","shell.execute_reply":"2025-04-16T20:28:42.012816Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"print(generate_headline(\"Breaking news\"))\nprint(generate_headline(\"new release\"))\nprint(generate_headline(\"white house\"))\nprint(generate_headline(\"wall street\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:28:50.099000Z","iopub.execute_input":"2025-04-16T20:28:50.099254Z","iopub.status.idle":"2025-04-16T20:28:52.737099Z","shell.execute_reply.started":"2025-04-16T20:28:50.099237Z","shell.execute_reply":"2025-04-16T20:28:52.736420Z"}},"outputs":[{"name":"stdout","text":"Breaking news awards ‘where are like covering someone made the same\nnew release from black police plan with cheese is now\nwhite house has been free of being a secret of\nwall street shakes off n y c ’s cities march in\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\n\n# Load dataset\narticles_path = '/kaggle/input/new-york-times-articles-comments-2020/nyt-articles-2020.csv'\ndf = pd.read_csv(articles_path, usecols=['headline'])\ndf.dropna(inplace=True)\n\n# Prepare text data\nheadlines = df['headline'].astype(str).tolist()\n\n# Tokenization with limited vocabulary\nvocab_size = 10000\ntokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\ntokenizer.fit_on_texts(headlines)\ntotal_words = vocab_size\n\n# Create input sequences\ninput_sequences = []\nfor headline in headlines:\n    token_list = tokenizer.texts_to_sequences([headline])[0]\n    for i in range(1, len(token_list)):\n        input_sequences.append(token_list[:i+1])\n\n# Limit sequences for memory safety\ninput_sequences = input_sequences[-100000:]\n\n# Pad sequences\nmax_sequence_length = max(len(seq) for seq in input_sequences)\ninput_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n\n# Split into input and output\nX, y = input_sequences[:, :-1], input_sequences[:, -1]\n\n# Build LSTM model\nmodel = Sequential([\n    Embedding(total_words, 64, input_length=max_sequence_length-1),\n    LSTM(64),\n    Dense(64, activation='relu'),\n    Dense(total_words, activation='softmax')\n])\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train model\nmodel.fit(X, y, epochs=30, verbose=1)\n\n# Temperature-based sampling\ndef sample_with_temperature(preds, temperature=1.0):\n    preds = np.asarray(preds).astype(\"float64\")\n    preds = np.log(preds + 1e-7) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\n# Headline generation function\ndef generate_headline(seed_text, next_words=10, temperature=1.0):\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n        preds = model.predict(token_list, verbose=0)[0]\n        predicted_index = sample_with_temperature(preds, temperature)\n        output_word = tokenizer.index_word.get(predicted_index, \"\")\n        if output_word and output_word != \"<OOV>\":\n            seed_text += \" \" + output_word\n    return seed_text\n\n# Example usage\nprint(generate_headline(\"tech stocks\", next_words=10, temperature=0.8))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:30:12.229477Z","iopub.execute_input":"2025-04-16T20:30:12.230102Z","iopub.status.idle":"2025-04-16T20:37:15.956865Z","shell.execute_reply.started":"2025-04-16T20:30:12.230075Z","shell.execute_reply":"2025-04-16T20:37:15.956198Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.0615 - loss: 7.3515\nEpoch 2/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.0756 - loss: 6.7725\nEpoch 3/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.1040 - loss: 6.4531\nEpoch 4/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.1190 - loss: 6.1891\nEpoch 5/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.1348 - loss: 5.9574\nEpoch 6/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.1437 - loss: 5.7511\nEpoch 7/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.1549 - loss: 5.5431\nEpoch 8/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.1664 - loss: 5.3867\nEpoch 9/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.1727 - loss: 5.2455\nEpoch 10/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.1798 - loss: 5.1022\nEpoch 11/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.1879 - loss: 4.9497\nEpoch 12/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.1910 - loss: 4.8452\nEpoch 13/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.2017 - loss: 4.7184\nEpoch 14/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.2074 - loss: 4.6138\nEpoch 15/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.2135 - loss: 4.4967\nEpoch 16/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.2213 - loss: 4.4009\nEpoch 17/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.2297 - loss: 4.3059\nEpoch 18/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.2401 - loss: 4.2012\nEpoch 19/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.2468 - loss: 4.1157\nEpoch 20/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.2554 - loss: 4.0443\nEpoch 21/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.2699 - loss: 3.9300\nEpoch 22/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.2769 - loss: 3.8678\nEpoch 23/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.2848 - loss: 3.8023\nEpoch 24/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.2922 - loss: 3.7370\nEpoch 25/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.3053 - loss: 3.6474\nEpoch 26/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.3105 - loss: 3.5855\nEpoch 27/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.3200 - loss: 3.5094\nEpoch 28/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.3274 - loss: 3.4625\nEpoch 29/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.3343 - loss: 3.4069\nEpoch 30/30\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.3447 - loss: 3.3325\ntech stocks play for campaign for office women have been than\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"\nprint(generate_headline(\"Breaking news\", next_words=10, temperature=0.8))\nprint(generate_headline(\"new release\", next_words=10, temperature=0.8))\nprint(generate_headline(\"white house\", next_words=10, temperature=0.8))\nprint(generate_headline(\"wall street\", next_words=10, temperature=0.8))\nprint(generate_headline(\"tech stocks\", next_words=10, temperature=0.8))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:37:15.957845Z","iopub.execute_input":"2025-04-16T20:37:15.958109Z","iopub.status.idle":"2025-04-16T20:37:18.423422Z","shell.execute_reply.started":"2025-04-16T20:37:15.958080Z","shell.execute_reply":"2025-04-16T20:37:18.422736Z"}},"outputs":[{"name":"stdout","text":"Breaking news five profile tries to fake pandemic us later it’s\nnew release about safety slave mail in ballots in 2 000 student\nwhite house primary to 900 years after the coronavirus doing voters really\nwall street rallies in america south 5 million 2 million weeks from\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"You doubled the vocabulary, giving the model more words to work with.\n\nThis can help capture more nuance and variety in headline generation.","metadata":{}},{"cell_type":"code","source":" New Addition: Word Repetition Check\nYou introduced a last_word tracker to avoid repeating the same word twice in a row:","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def generate_headline(seed_text, next_words=10, temperature=1.0):\n    last_word = None\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n        preds = model.predict(token_list, verbose=0)[0]\n        predicted_index = sample_with_temperature(preds, temperature)\n        output_word = tokenizer.index_word.get(predicted_index, \"\")\n\n        if output_word and output_word != \"<OOV>\" and output_word != last_word:\n            seed_text += \" \" + output_word\n            last_word = output_word\n\n    return seed_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:38:45.365740Z","iopub.execute_input":"2025-04-16T20:38:45.366073Z","iopub.status.idle":"2025-04-16T20:38:45.371559Z","shell.execute_reply.started":"2025-04-16T20:38:45.366054Z","shell.execute_reply":"2025-04-16T20:38:45.370797Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\nprint(generate_headline(\"Breaking news\", next_words=30, temperature=0.8))\nprint(generate_headline(\"new release\", next_words=30, temperature=0.8))\nprint(generate_headline(\"white house\", next_words=30, temperature=0.8))\nprint(generate_headline(\"wall street\", next_words=30, temperature=0.8))\nprint(generate_headline(\"tech stocks\", next_words=30, temperature=0.8))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:39:20.354939Z","iopub.execute_input":"2025-04-16T20:39:20.355231Z","iopub.status.idle":"2025-04-16T20:39:29.310570Z","shell.execute_reply.started":"2025-04-16T20:39:20.355211Z","shell.execute_reply":"2025-04-16T20:39:29.309993Z"}},"outputs":[{"name":"stdout","text":"Breaking news terrify in breonna taylor case machine else have to begin four bowl allegation t athletes tries to reopen music dies at 94 thanksgiving bond this medical reds brace for the\nnew release to not the supreme court rules why did it work when you think it’s like there are going online to haunt our dog promised country seeking live air\nwhite house g o p u s finished head by coronavirus surges republicans really see it what should fall good months in four states study for george floyd death tests and\nwall street rallies but the trump administration sees each other king in a conservative wasn’t than me stage from the n to wisconsin that ’ new york stop old filmmaker he t\ntech stocks face a new risks of u s to fight away about u s won by and lands it to back caught with week people in the times this\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from transformers import pipeline\n\n# Load zero-shot classification pipeline\nclassifier = pipeline(\"zero-shot-classification\")\n\n# Semantic safety check function\ndef is_semantically_safe(headline, unsafe_topics=[\"violence\", \"politics\", \"tragedy\"]):\n    result = classifier(headline, candidate_labels=unsafe_topics)\n    top_label = result[\"labels\"][0]\n    if result[\"scores\"][0] > 0.5:\n        return False\n    return True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:44:33.604222Z","iopub.execute_input":"2025-04-16T20:44:33.604534Z","iopub.status.idle":"2025-04-16T20:44:58.130731Z","shell.execute_reply.started":"2025-04-16T20:44:33.604513Z","shell.execute_reply":"2025-04-16T20:44:58.130150Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"604f3e3523684c4cb708a97c34b370bd"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b238b4d9dff4c70b59c73f9dcaf3a5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1aaad230ade4007b04e0e73c8bef6b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49a1f7a06ea74e8c8c1b75e5df0b9a4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"426806f189ce408db567abaf75b005d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1800b4532a804d15a1f788c3c953d02c"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def generate_safe_headlines(seed_text, count=5, next_words=10, temperature=1.0):\n    headlines = []\n    attempts = 0\n    max_attempts = count * 10  # avoid infinite loop\n\n    while len(headlines) < count and attempts < max_attempts:\n        generated = generate_headline(seed_text, next_words, temperature)\n        if is_semantically_safe(generated):\n            headlines.append(generated)\n        attempts += 1\n\n    return headlines\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:45:04.031293Z","iopub.execute_input":"2025-04-16T20:45:04.032075Z","iopub.status.idle":"2025-04-16T20:45:04.036381Z","shell.execute_reply.started":"2025-04-16T20:45:04.032049Z","shell.execute_reply":"2025-04-16T20:45:04.035686Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"safe_headlines = generate_safe_headlines(\"technology trends\", count=5, temperature=0.8)\nfor i, h in enumerate(safe_headlines, 1):\n    print(f\"{i}. {h}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:45:11.591271Z","iopub.execute_input":"2025-04-16T20:45:11.591527Z","iopub.status.idle":"2025-04-16T20:45:21.068059Z","shell.execute_reply.started":"2025-04-16T20:45:11.591508Z","shell.execute_reply":"2025-04-16T20:45:21.067152Z"}},"outputs":[{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"1. technology trends the vibe club takes back to bases in\n2. technology trends the days of the coronavirus study finds also 2nd\n3. technology trends the state adjusts you face paper and former prude’s d\n4. technology trends from his army account for the birth\n5. technology trends a half community of ‘the crown’ is covid 19 question\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"def generate_safe_headline(seed_text, next_words=10, temperature=1.0):\n    max_attempts = 10\n    attempts = 0\n\n    while attempts < max_attempts:\n        generated = generate_headline(seed_text, next_words, temperature)\n        if is_semantically_safe(generated):\n            return generated\n        attempts += 1\n\n    return \"Could not generate a safe headline.\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:46:08.292732Z","iopub.execute_input":"2025-04-16T20:46:08.293046Z","iopub.status.idle":"2025-04-16T20:46:08.297618Z","shell.execute_reply.started":"2025-04-16T20:46:08.293026Z","shell.execute_reply":"2025-04-16T20:46:08.296908Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"print(generate_safe_headline(\"Breaking news\", next_words=19, temperature=0.7))\nprint(generate_safe_headline(\"new release\", next_words=19, temperature=0.7))\nprint(generate_safe_headline(\"white house\", next_words=19, temperature=0.7))\nprint(generate_safe_headline(\"wall street\", next_words=19, temperature=0.7))\nprint(generate_safe_headline(\"Btech stocks\", next_words=19, temperature=0.7))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:49:21.306222Z","iopub.execute_input":"2025-04-16T20:49:21.306961Z","iopub.status.idle":"2025-04-16T20:49:48.155829Z","shell.execute_reply.started":"2025-04-16T20:49:21.306934Z","shell.execute_reply":"2025-04-16T20:49:48.155157Z"}},"outputs":[{"name":"stdout","text":"Breaking news russia warns to reopen he goes to the at english weight is coming fever people can’t meet n\nnew release from drug in a virus is breaking up against my most vulnerable t d to the last\nCould not generate a safe headline.\nwall street rallies for an algorithm vote looked and what is jobless benefits about door on flash floods\nBtech stocks face the u s a simple agenda without months round more another business for voting in the pandemic\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"model.save(\"your_model_path.h5\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:56:56.479530Z","iopub.execute_input":"2025-04-16T20:56:56.479820Z","iopub.status.idle":"2025-04-16T20:56:56.541568Z","shell.execute_reply.started":"2025-04-16T20:56:56.479797Z","shell.execute_reply":"2025-04-16T20:56:56.540777Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import pickle\nwith open(\"tokenizer.pkl\", \"wb\") as f:\n    pickle.dump(tokenizer, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:57:18.398459Z","iopub.execute_input":"2025-04-16T20:57:18.399057Z","iopub.status.idle":"2025-04-16T20:57:18.414288Z","shell.execute_reply.started":"2025-04-16T20:57:18.399017Z","shell.execute_reply":"2025-04-16T20:57:18.413789Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model.save('/kaggle/working/headline_model.h5')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:58:00.498013Z","iopub.execute_input":"2025-04-16T20:58:00.498681Z","iopub.status.idle":"2025-04-16T20:58:00.558932Z","shell.execute_reply.started":"2025-04-16T20:58:00.498659Z","shell.execute_reply":"2025-04-16T20:58:00.558038Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import pickle\n\nwith open('/kaggle/working/tokenizer.pkl', 'wb') as f:\n    pickle.dump(tokenizer, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:58:08.772451Z","iopub.execute_input":"2025-04-16T20:58:08.772732Z","iopub.status.idle":"2025-04-16T20:58:08.791329Z","shell.execute_reply.started":"2025-04-16T20:58:08.772712Z","shell.execute_reply":"2025-04-16T20:58:08.790497Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink('/kaggle/working/headline_model.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:58:15.352156Z","iopub.execute_input":"2025-04-16T20:58:15.352415Z","iopub.status.idle":"2025-04-16T20:58:15.357506Z","shell.execute_reply.started":"2025-04-16T20:58:15.352397Z","shell.execute_reply":"2025-04-16T20:58:15.356935Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/headline_model.h5","text/html":"<a href='/kaggle/working/headline_model.h5' target='_blank'>/kaggle/working/headline_model.h5</a><br>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Create download link for the saved tokenizer\nFileLink('/kaggle/working/tokenizer.pkl')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:59:02.904479Z","iopub.execute_input":"2025-04-16T20:59:02.904792Z","iopub.status.idle":"2025-04-16T20:59:02.910167Z","shell.execute_reply.started":"2025-04-16T20:59:02.904742Z","shell.execute_reply":"2025-04-16T20:59:02.909539Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/tokenizer.pkl","text/html":"<a href='/kaggle/working/tokenizer.pkl' target='_blank'>/kaggle/working/tokenizer.pkl</a><br>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}